
# The PTF image built from different branches may be incompatible. The ptf_imagetag variable added here is to
# support using different PTF images for different branches. When the ptf_imagetag variable is not specified,
# the PTF image with default "latest" tag will be used. When a specific PTF image version is required, we can
# specify a value for the ptf_imagetag variable somewhere, for example, specify from command line:
#    ./testbed-cli.sh add-topo <testbed_name>-<topo> vault -e ptf_imagetag=201811
# By using this practice, we suggest to add different tags for different PTF image versions in docker registry.
- name: Set default value for ptf_imagetag
  set_fact:
    ptf_imagetag: "latest"
  when: ptf_imagetag is not defined

- name: set "PTF" container type, by default
  set_fact:
    container_type: "PTF"

- name: set "API-SERVER" container type if Keysight Api Server is used
  set_fact:
    container_type: "API-SERVER"
  when: ptf_imagename is defined and ptf_imagename == "docker-keysight-api-server"

- name: set "IxANVL-CONF-TESTER" container type if Keysight IxANVL is used
  set_fact:
    container_type: "IxANVL-CONF-TESTER"
  when: ptf_imagename is defined and ptf_imagename == "docker-ptf-anvl"

- name: Try to login into docker registry
  docker_login:
    registry_url: "{{ docker_registry_host }}"
    username: "{{ docker_registry_username }}"
    password: "{{ docker_registry_password }}"
  become: yes
  when: docker_registry_username is defined and docker_registry_password is defined

- name: Deploy Keysight API Server container
  block:
    - name: Get Keysight API Server container status
      docker_container_info:
        name: apiserver
      register: keysight_api_server_container_status

    - debug:
        msg: "[ WARNING ] Keysight API server container is already running hence not deploying again."
      when:
        - keysight_api_server_container_status['exists']
        - keysight_api_server_container_status['container']['State']['Status'] == 'running'

    - name: Start Keysight API Server container
      block:
        - name: Assign rest port
          set_fact:
            rest_port: secret_group_vars['ixia_api_server']['rest_port']
          when:
            - secret_group_vars is defined
            - secret_group_vars['ixia_api_server'] is defined
            - secret_group_vars['ixia_api_server']['rest_port'] is defined

        - name: default secret_group_vars if not defined
          set_fact:
            rest_port: 443
          when: >
            secret_group_vars is not defined
            or secret_group_vars['ixia_api_server'] is not defined
            or secret_group_vars['ixia_api_server']['rest_port'] is not defined

        - name: Pull and start Keysight API Server container
          docker_container:
            name: apiserver
            image: "{{ docker_registry_host }}/{{ ptf_imagename }}:{{ ptf_imagetag }}"
            pull: yes
            state: started
            restart: no
            published_ports: "{{ rest_port }}:443"
            detach: True
            capabilities:
              - net_admin
            privileged: yes
            memory: 8G
            memory_swap: 8G
          become: yes

        - name: Update ptf password
          include_tasks: update_ptf_password.yml

        - name: Bind ptf_ip to keysight_api_server
          vm_topology:
            cmd: "bind_keysight_api_server_ip"
            ptf_mgmt_ip_addr: "{{ ptf_ip }}"
            ptf_mgmt_ipv6_addr: "{{ ptf_ipv6 }}"
            ptf_mgmt_ip_gw: "{{ mgmt_gw }}"
            ptf_mgmt_ipv6_gw: "{{ mgmt_gw_v6 | default(None) }}"
            ptf_extra_mgmt_ip_addr: "{{ ptf_extra_mgmt_ip.split(',') | default([]) }}"
            mgmt_bridge: "{{ mgmt_bridge }}"
            vm_names: ""
          become: yes

      when: >
        not keysight_api_server_container_status['exists']
        or (keysight_api_server_container_status['exists']
        and keysight_api_server_container_status['container']['State']['Status'] != 'running')

  when: container_type == "API-SERVER"

- name: Start Keysight IxANVL container
  block:
    - name: Pull and start Keysight IxANVL container
      docker_container:
        name: ptf_anvl
        image: "{{ docker_registry_host }}/{{ ptf_imagename }}:{{ ptf_imagetag }}"
        pull: yes
        state: started
        restart: no
        detach: True
        network_mode: none
        capabilities:
          - net_admin
        privileged: yes
        memory: 8G
        memory_swap: 8G
      become: yes

    - name: Get dut ports
      include_tasks: get_dut_port.yml
      loop: "{{ duts_name.split(',') }}"
      loop_control:
        loop_var: dut_name

    - name: Create vlan ports for dut
      include_tasks: create_dut_port.yml
      when: external_port is defined
      loop: "{{ duts_name.split(',') }}"
      loop_control:
        loop_var: dut_name

    - name: Bind topology {{ topo }} to VMs. base vm = {{ VM_base }}
      vm_topology:
        cmd: "bind"
        vm_names: ""
        vm_set_name: "{{ vm_set_name }}"
        topo: "{{ topology }}"
        ptf_mgmt_ip_addr: "{{ ptf_ip }}"
        ptf_mgmt_ipv6_addr: "{{ ptf_ipv6 }}"
        ptf_mgmt_ip_gw: "{{ mgmt_gw }}"
        ptf_mgmt_ipv6_gw: "{{ mgmt_gw_v6 | default(None) }}"
        ptf_extra_mgmt_ip_addr: "{{ ptf_extra_mgmt_ip.split(',') | default([]) }}"
        ptf_bp_ip_addr: "{{ ptf_bp_ip }}"
        ptf_bp_ipv6_addr: "{{ ptf_bp_ipv6 }}"
        mgmt_bridge: "{{ mgmt_bridge }}"
        duts_fp_ports: "{{ duts_fp_ports }}"
        duts_mgmt_port: "{{ duts_mgmt_port }}"
        duts_name: "{{ duts_name.split(',') }}"
        fp_mtu: "{{ fp_mtu_size }}"
        max_fp_num: "{{ max_fp_num }}"
      become: yes

  when: container_type == "IxANVL-CONF-TESTER"

- name: Start PTF container
  block:
  - name: Create ptf container ptf_{{ vm_set_name }}
    docker_container:
      name: ptf_{{ vm_set_name }}
      image: "{{ docker_registry_host }}/{{ ptf_imagename }}:{{ ptf_imagetag }}"
      # Set pull to 'missing' when ptf_modified is True (PR test with preloaded image)
      # to avoid pulling and overwriting the local image. For nightly tests where
      # ptf_modified is False/undefined, use 'always' to always pull the latest image.
      # The ptf_modified flag is passed from Azure Pipelines through Elastictest's
      # add_topo_params as "-e ptf_modified=True" when testing PR built docker-ptf images.
      pull: "{{ 'missing' if (ptf_modified | default(false) | bool) else 'always' }}"
      state: started
      restart: no
      network_mode: none
      detach: True
      capabilities:
        - net_admin
      privileged: yes
      memory: 32G
      memory_swap: 64G
    become: yes

  - name: Update ptf password
    include_tasks: update_ptf_password.yml

  - name: Enable ipv6 for docker container ptf_{{ vm_set_name }}
    command: docker exec -i ptf_{{ vm_set_name }} sysctl -w net.ipv6.conf.all.disable_ipv6=0
    become: yes

  - name: Set ipv6 route max size of ptf_{{ vm_set_name }}
    command: docker exec -i ptf_{{ vm_set_name }} sysctl -w net.ipv6.route.max_size=168000
    become: yes

  - name: Don't accept ipv6 router advertisements for docker container ptf_{{ vm_set_name }}
    command: docker exec -i ptf_{{ vm_set_name }} sysctl -w net.ipv6.conf.default.accept_ra=0
    become: yes

  - name: Create file to store dut type in PTF
    command: docker exec -i ptf_{{ vm_set_name }} sh -c 'echo {{ hostvars[duts_name.split(',')[0]]['type'] }} > /sonic/dut_type.txt'
    when:
      - hostvars[duts_name.split(',')[0]] is defined
      - hostvars[duts_name.split(',')[0]].type is defined
    become: yes

  - name: Create file to store asic type in PTF
    command: docker exec -i ptf_{{ vm_set_name }} sh -c 'echo {{ hostvars[duts_name.split(',')[0]]['asic_type'] }} > /sonic/asic_type.txt'
    when:
      - hostvars[duts_name.split(',')[0]] is defined
      - hostvars[duts_name.split(',')[0]].asic_type is defined
    become: yes

  - name: Get dut ports
    include_tasks: get_dut_port.yml
    loop: "{{ duts_name.split(',') }}"
    loop_control:
      loop_var: dut_name

  - name: Create vlan ports for dut
    include_tasks: create_dut_port.yml
    when: external_port is defined
    loop: "{{ duts_name.split(',') }}"
    loop_control:
      loop_var: dut_name

  - debug: msg="{{ duts_fp_ports }}"
  - debug: msg="{{ duts_mgmt_port }}"

  - include_tasks: add_ceos_list.yml
    when: vm_type is defined and vm_type == "ceos"

  - include_tasks: add_csonic_list.yml
    when: vm_type is defined and (vm_type == "csonic")

  - name: Bind topology {{ topo }} to VMs. base vm = {{ VM_base }}
    vm_topology:
      cmd: "bind"
      vm_set_name: "{{ vm_set_name }}"
      topo: "{{ topology }}"
      vm_names: "{{ VM_targets }}"
      vm_base: "{{ VM_base }}"
      vm_type: "{{ vm_type }}"
      vm_properties: "{{ vm_properties if vm_properties is defined else omit }}"
      ptf_mgmt_ip_addr: "{{ ptf_ip }}"
      ptf_mgmt_ipv6_addr: "{{ ptf_ipv6 }}"
      ptf_mgmt_ip_gw: "{{ mgmt_gw }}"
      ptf_mgmt_ipv6_gw: "{{ mgmt_gw_v6 | default(None) }}"
      ptf_extra_mgmt_ip_addr: "{{ ptf_extra_mgmt_ip.split(',') | default([]) }}"
      ptf_bp_ip_addr: "{{ ptf_bp_ip }}"
      ptf_bp_ipv6_addr: "{{ ptf_bp_ipv6 }}"
      mgmt_bridge: "{{ mgmt_bridge }}"
      duts_fp_ports: "{{ duts_fp_ports }}"
      duts_midplane_ports: "{{ duts_midplane_ports }}"
      duts_inband_ports: "{{ duts_inband_ports }}"
      duts_mgmt_port: "{{ duts_mgmt_port }}"
      duts_name: "{{ duts_name.split(',') }}"
      fp_mtu: "{{ fp_mtu_size }}"
      max_fp_num: "{{ max_fp_num }}"
      netns_mgmt_ip_addr: "{{ netns_mgmt_ip if netns_mgmt_ip is defined else omit }}"
      dut_interfaces: "{{ dut_interfaces | default('') }}"
      is_vs_chassis: "{{ is_vs_chassis | default(false) }}"
    become: yes
    when: not enable_async

  - name: Bind topology {{ topo }} to VMs. base vm = {{ VM_base }} (async mode)
    loop: "{{ VM_targets|flatten(levels=1) }}"
    loop_control:
      loop_var: current_vm_name
    vm_topology:
      cmd: "bind"
      vm_set_name: "{{ vm_set_name }}"
      topo: "{{ topology }}"
      vm_names: "{{ VM_targets }}"
      current_vm_name: "{{ current_vm_name }}"
      vm_base: "{{ VM_base }}"
      vm_type: "{{ vm_type }}"
      vm_properties: "{{ vm_properties if vm_properties is defined else omit }}"
      ptf_mgmt_ip_addr: "{{ ptf_ip }}"
      ptf_mgmt_ipv6_addr: "{{ ptf_ipv6 }}"
      ptf_mgmt_ip_gw: "{{ mgmt_gw }}"
      ptf_mgmt_ipv6_gw: "{{ mgmt_gw_v6 | default(None) }}"
      ptf_extra_mgmt_ip_addr: "{{ ptf_extra_mgmt_ip.split(',') | default([]) }}"
      ptf_bp_ip_addr: "{{ ptf_bp_ip }}"
      ptf_bp_ipv6_addr: "{{ ptf_bp_ipv6 }}"
      mgmt_bridge: "{{ mgmt_bridge }}"
      duts_fp_ports: "{{ duts_fp_ports }}"
      duts_midplane_ports: "{{ duts_midplane_ports }}"
      duts_inband_ports: "{{ duts_inband_ports }}"
      duts_mgmt_port: "{{ duts_mgmt_port }}"
      duts_name: "{{ duts_name.split(',') }}"
      fp_mtu: "{{ fp_mtu_size }}"
      max_fp_num: "{{ max_fp_num }}"
      netns_mgmt_ip_addr: "{{ netns_mgmt_ip if netns_mgmt_ip is defined else omit }}"
      dut_interfaces: "{{ dut_interfaces | default('') }}"
      is_vs_chassis: "{{ is_vs_chassis | default(false) }}"
    become: yes
    async: 3600
    poll: 0
    throttle: 50
    register: async_bind_vm
    when: enable_async

  - name: Wait for bind tasks to complete
    become: yes
    async_status:
      jid: "{{ async_bind_vm_item.ansible_job_id }}"
    loop: "{{ async_bind_vm.results }}"
    loop_control:
      loop_var: async_bind_vm_item
    register: async_bind_topology_poll_results
    until: async_bind_topology_poll_results.finished
    retries: 30
    delay: 60
    when: enable_async

  - name: Bind topology {{ topo }} to DPUs.
    vm_topology:
      cmd: "bind"
      vm_set_name: "{{ vm_set_name }}"
      topo: "{{ topology }}"
      vm_names: "{{ VM_hosts }}"
      vm_base: "{{ VM_base }}"
      vm_type: "vsonic"
      vm_properties: "{{ vm_properties if vm_properties is defined else omit }}"
      ptf_mgmt_ip_addr: "{{ ptf_ip }}"
      ptf_mgmt_ipv6_addr: "{{ ptf_ipv6 }}"
      ptf_mgmt_ip_gw: "{{ mgmt_gw }}"
      ptf_mgmt_ipv6_gw: "{{ mgmt_gw_v6 | default(None) }}"
      ptf_extra_mgmt_ip_addr: "{{ ptf_extra_mgmt_ip.split(',') | default([]) }}"
      ptf_bp_ip_addr: "{{ ptf_bp_ip }}"
      ptf_bp_ipv6_addr: "{{ ptf_bp_ipv6 }}"
      mgmt_bridge: "{{ mgmt_bridge }}"
      duts_fp_ports: "{{ duts_fp_ports }}"
      duts_mgmt_port: "{{ duts_mgmt_port }}"
      duts_name: "{{ duts_name.split(',') }}"
      fp_mtu: "{{ fp_mtu_size }}"
      max_fp_num: "{{ max_fp_num }}"
      netns_mgmt_ip_addr: "{{ netns_mgmt_ip if netns_mgmt_ip is defined else omit }}"
      is_dpu: true
    become: yes
    when: dpu_targets is defined and dpu_targets | length > 0

  - name: Change MAC address for PTF interfaces
    include_tasks: ptf_change_mac.yml
    when: topo != 'fullmesh'

  # ptf container may reuse the same ip address with a new random mac address
  # for ptf container's mgmt network interface, so we need to send gratuitous
  # ARP to announce PTF container MAC to network
  - name: Send gratuitous ARP to announce PTF container MAC to network
    shell: |
      docker exec -i ptf_{{ vm_set_name }} python3 << 'GARP_EOF'
      from scapy.all import *
      my_ip = "{{ ptf_ip.split('/')[0] }}"
      gw_ip = "{{ mgmt_gw }}"
      my_mac = get_if_hwaddr("mgmt")
      # Send broadcast ARP reply (gratuitous ARP) to announce IP->MAC mapping
      pkt = Ether(dst="ff:ff:ff:ff:ff:ff") / ARP(op=2, psrc=my_ip, hwsrc=my_mac, pdst=gw_ip, hwdst="ff:ff:ff:ff:ff:ff")
      sendp(pkt, iface="mgmt", count=10, verbose=0)
      print("Gratuitous ARP sent successfully")
      GARP_EOF
    become: yes
    failed_when: false

  - name: Wait for PTF container network to become fully operational
    shell: |
      echo "Waiting for PTF network to stabilize..."
      for attempt in $(seq 1 30); do
        if docker exec ptf_{{ vm_set_name }} ping -c 1 -W 2 {{ mgmt_gw }} | grep -q "1 received"; then
          echo "Network ready after $attempt attempts"
          exit 0
        fi
        echo "Attempt $attempt/30: Network not ready, waiting 2 seconds..."
        sleep 2
      done
      echo "Warning: Network not ready after 60 seconds, continuing anyway..."
      exit 1
    become: yes
    register: network_ready
    failed_when: false

  - name: Display PTF network readiness status
    debug:
      msg: "stdout: {{ network_ready.stdout_lines }} stderr: {{ network_ready.stderr_lines }}"

  - name: Start ptf_tgen service
    include_tasks: start_ptf_tgen.yml
    when: topo == 'fullmesh'

  - name: Start PTF portchannel service
    include_tasks: ptf_portchannel.yml
    vars:
      ptf_portchannel_action: start

  - name: Announce routes
    include_tasks: announce_routes.yml
    when:
      - topo != 'fullmesh'
      - not 'ptf' in topo
      - not 'cable' in topo

  - name: Start mux simulator
    include_tasks: control_mux_simulator.yml
    vars:
      mux_simulator_action: start
    when: "'dualtor' in topo"

  - name: Start nic simulator
    include_tasks: control_nic_simulator.yml
    vars:
      nic_simulator_action: start
    when: topology.host_interfaces_active_active is defined and topology.host_interfaces_active_active|length > 0

  - name: Start tacacs+ daily daemon
    include_tasks: start_tacacs_daily_daemon.yml

  when: container_type == "PTF"

- name: Save PTF image
  block:
  - shell: docker tag "{{ docker_registry_host }}/{{ ptf_imagename }}:{{ ptf_imagetag }}" docker-ptf
  - shell: docker save -o {{ root_path }}/images/docker-ptf.tar docker-ptf
  - fetch: src={{ root_path }}/images/docker-ptf.tar dest=docker-ptf.tar flat=yes
  - shell: rm -f {{ root_path }}/images/docker-ptf.tar
  run_once: yes
  become: yes
  when: vm_type is defined and vm_type == "vsonic" and ptf_on_neighbor is defined and ptf_on_neighbor|bool == true
