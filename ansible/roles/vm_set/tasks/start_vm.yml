# Define respin_vm to override the test for VM existence.
# Any VM defined in the list will be destroyed and restarted.
# This provides a manual method to respin some VMs when they
# are down.
#
# I encountered VM down when deploying topology. Without a
# method to respin these VMs, the other way is to reboot/cleanup
# server and restart all VMs. The later method disrupts all
# topologies on the server.
#
# After respining individual VMs, the affected topology needs to
# be removed and deployed again.

- set_fact:
    disk_image_name: "{{ vm_type }}_{{ vm_name }}_hdd.vmdk"
    vm_xml_template: "arista.xml.j2"
  when: (vm_type | lower) == "veos"

- set_fact:
    disk_image_name: "{{ vm_type }}_{{ vm_name }}.img"
    vm_xml_template: "sonic_vm.xml.j2"
  when: (vm_type | lower) == "vsonic"

- set_fact:
    disk_image: "{{ disk_image_dir }}/{{ disk_image_name }}"

- set_fact:
    respin_vms: []
  when: respin_vms is not defined

- name: Device debug output
  debug: msg="hostname = {{ hostname }} vm_type = {{ vm_type }} serial port = {{ serial_port }} ip = {{ mgmt_ip_address }}"

- name: Check destination file existance
  stat: path={{ disk_image }}
  register: file_stat

- name: Copy arista disk image for {{ hostname }}
  copy: src={{ src_disk_image }} dest={{ disk_image }} remote_src=True
  when: not file_stat.stat.exists

- name: Define vm {{ vm_name }}
  virt: name={{ vm_name }}
        command=define
        xml="{{ lookup('template', 'templates/{{ vm_xml_template }}') }}"
        uri=qemu:///system
  when: vm_name not in vm_list_defined.list_vms
  become: yes

- name: Destroy vm {{ vm_name }} if it requires fix
  virt: name={{ vm_name }}
        command=destroy
        uri=qemu:///system
  when: vm_name in respin_vms
  become: yes
  ignore_errors: true

- name: Start vm {{ vm_name }}
  virt: name={{ vm_name }}
        state=running
        uri=qemu:///system
  when: vm_name not in vm_list_running.list_vms or vm_name in respin_vms
  become: yes

# Some testbed may have issue of starting multiple VMs in parallel, this pause is a workaround for this issue
# A better solution should have been used. But the current used ansible v2.0 has issue with nested loops:
# https://github.com/ansible/ansible/issues/14146 So, we can only use this simple workaround for the parallel
# VM starting issue.

- name: Find out VM index
  set_fact:
    vm_index: "{{ VM_hosts.index(vm_name)|int + 1 }}"

- name: "Pause after started every {{ batch_size }} VMs"
  pause: seconds="{{ interval }}"
  when:
    - "{{ vm_index }} % {{ batch_size }} == 0"
    - "{{ interval }} > 0"
