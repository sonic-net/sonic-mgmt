# This Playbook run time generate matching configuration file for SONiC switch(Minigraph) based on a specific testbed topology specified in testbed.csv
# When user call testbed-cli to deploy a testbed topology, use this playbook to generate matching SONiC minigraph file and deploy it into SONiC switch under test.
# Or when you know your topology name, you may use this playbook alone to generate a minigraph matching your topology name without deploy it.
#
# VM Topologies are defined inside of vars/ directory in files vars/topo_{{ topology_name}}.yml
#  Every topology should have a name to distinct one topology from another on the server
#  Every topology contains a ptf container which will be used as placeholder for the injected interfaces from VMs, or direct connections to PTF host
# VMs inventory file is also required to have all VMs ready for generating the minigraph file
# VMs inventory is in file 'veos'
#
# Template files for generating minigraph.xml are defined in template/topo directory
#
# To generate and deploy minigraph for SONiC switch matching the VM topology please use following command
# ansible-playbook -i lab config_sonic_basedon_testbed.yml -l sonic_dut_name -e vm_base=VM0300 -e topo=t0 [-e deploy=true -e save=true]
# ansible-playbook -i lab config_sonic_basedon_testbed.yml -l sonic_dut_name -e testbed_name=vms1-1 [-e deploy=true -e save=true]

# Parameters
# -l str-msn2700-01          - the sonic_dut_name you are going to generate minigraph for
# -e vm_base=VM0300          - the VM name which is used to as base to calculate VM name for this set
# -e topo=t0                 - the name of topology to generate minigraph file
# -e testbed_name=vms1-1     - the testbed name specified in testbed.csv file
#                              (if you give 'testbed_name' option, will use info from testbed and ignore topo and vm_base options)
# -e vm_file=veos            - the virtual machine file name
# -e deploy=True             - if deploy the newly generated minigraph to the target DUT, default is false if not defined
# -e save=True               - if save the newly generated minigraph to the target DUT as startup-config, default is false if not defined
#
# After minigraph.xml is generated, the playbook will replace the original minigraph file under ansible/minigraph/ with the newly generated minigraph file for the SONiC device.
# The playbook will based on deploy=True or False to decide if load the SONiC device with new minigraph or not.
# If deploy=true, the playbook will apply the newly generated minigraph to the SONiC switch
# If save=true, the playbook will save the newly generated minigraph to SONiC switch as startup-config
#
####################################################################################################################################################################################

- hosts: sonic
  gather_facts: no
  tasks:

  - block:
    - name: set default testbed file
      set_fact:
        testbed_file: testbed.yaml
      when: testbed_file is not defined

    - name: Gathering testbed information
      test_facts: testbed_name="{{ testbed_name }}" testbed_file="{{ testbed_file }}"
      delegate_to: localhost

    - fail: msg="The DUT you are trying to run test does not belongs to this testbed"
      when: inventory_hostname not in testbed_facts['duts']

    - name: Set default num_asic
      set_fact:
        num_asics: 1
      when: num_asics is not defined

    - name: Set default dut index
      set_fact:
        dut_index: "{{ testbed_facts['duts_map'][inventory_hostname]|int }}"

    - name: set testbed_type
      set_fact:
        topo: "{{ testbed_facts['topo'] }}"

    - name: set ptf image name
      set_fact:
        ptf_image: "{{ testbed_facts['ptf_image_name'] }}"

    - name: check if testbed is an ixia testbed
      set_fact:
        is_ixia_testbed: "{{ true if ptf_image == 'docker-keysight-api-server' else false }}"

    - name: set vm
      set_fact:
        vm_base: "{% if testbed_facts['vm_base'] != '' %}{{ testbed_facts['vm_base'] }}{% else %}''{% endif %}"
    when: testbed_name is defined

  - name: find supervisor dut of testbed
    set_fact:
      sup_dut: "{{ item | default(None) }}"
    when: hostvars[item]['card_type'] is defined and hostvars[item]['card_type'] == 'supervisor'
    loop: "{{ testbed_facts['duts'] }}"

  - name: Get asics_present of supervisor dut
    set_fact:
      asics_present: "{{ hostvars[sup_dut]['asics_present'] | default([]) }}"
    when: sup_dut is defined and hostvars[sup_dut]['asics_present'] is defined

  - topo_facts: topo={{ topo }} hwsku={{ hwsku }} testbed_name={{ testbed_name | default(None) }} asics_present={{ asics_present | default([]) }} card_type={{ card_type | default('fixed') }}
    delegate_to: localhost

  - name: get connection graph if defined for dut (ignore any errors)
    conn_graph_facts: host="{{ inventory_hostname }}" ignore_errors=true
    delegate_to: localhost
    ignore_errors: true

  - name: find interface name mapping and individual interface speed if defined from dut
    port_alias:
      hwsku: "{{ hwsku }}"
      card_type: "{{ card_type | default('fixed') }}"
      hostname: "{{ inventory_hostname | default('') }}"
      switchids: "{{ switchids | default([]) }}"
    when: deploy is defined and deploy|bool == true

  - name: find interface name mapping and individual interface speed if defined with local data
    port_alias:
      hwsku: "{{ hwsku }}"
      num_asic: "{{ num_asics }}"
      card_type: "{{ card_type | default('fixed') }}"
      hostname: "{{ inventory_hostname | default('') }}"
      switchids: "{{ switchids | default([]) }}"
      slotid: "{{ slot_num | default(None) }}"
    delegate_to: localhost
    when: deploy is not defined or deploy|bool == false

  - name: find and generate fabric ASIC information
    fabric_info:
      num_fabric_asic: "{{ num_fabric_asics | default(0) }}"
      asics_host_basepfx: "{{ asics_host_ip | default(None) }}"
      asics_host_basepfx6: "{{ asics_host_ipv6 | default(None) }}"
    delegate_to: localhost

  - name: set all VoQ system ports information
    set_fact:
      all_sysports: "{{ all_sysports | default( [] ) + hostvars[item]['sysports'] }}"
    when: hostvars[item]['sysports'] is defined
    loop: "{{ ansible_play_batch }}"

  - name: set all v4 Inband Ip information for iBGP chassis voq
    set_fact:
      all_inbands: "{{ all_inbands | default( {} ) | combine( { item : hostvars[item]['voq_inband_ip']}) }}"
    when: hostvars[item]['voq_inband_ip'] is defined
    loop: "{{ ansible_play_batch }}"

  - name: set all v6 Inband Ip information for iBGP chassis voq
    set_fact:
      all_inbands_ipv6: "{{ all_inbands_ipv6 | default( {} ) | combine( { item : hostvars[item]['voq_inband_ipv6']}) }}"
    when: hostvars[item]['voq_inband_ipv6'] is defined
    loop: "{{ ansible_play_batch }}"

  - name: set all Loopback4096 information for iBGP chassis
    set_fact:
      all_loopback4096: "{{ all_loopback4096 | default( {} ) | combine( { item : hostvars[item]['loopback4096_ip']}) }}"
    when: hostvars[item]['loopback4096_ip'] is defined
    loop: "{{ ansible_play_batch }}"

  - name: set all Loopback4096 ipv6 information for iBGP chassis
    set_fact:
      all_loopback4096_ipv6: "{{ all_loopback4096_ipv6 | default( {} ) | combine( { item : hostvars[item]['loopback4096_ipv6']}) }}"
    when: hostvars[item]['loopback4096_ipv6'] is defined
    loop: "{{ ansible_play_batch }}"

  - name: set all slot information for chassis
    set_fact:
      all_slots: "{{ all_slots | default( {} ) | combine( { item : hostvars[item]['slot_num']}) }}"
    when: hostvars[item]['slot_num'] is defined
    loop: "{{ ansible_play_batch }}"

  - name: find all enabled host_interfaces
    set_fact:
      host_if_indexes: "{{ vm_topo_config['host_interfaces_by_dut'][dut_index|int] | difference(vm_topo_config['disabled_host_interfaces_by_dut'][dut_index|int]) }}"

  - name: find all vlan interface names for T0 topology
    set_fact:
      vlan_intfs: "{{ vlan_intfs|default([]) + [port_alias[item]] }}"
    with_items: "{{ host_if_indexes }}"
    when: "('host_interfaces_by_dut' in vm_topo_config) and ('tor' in vm_topo_config['dut_type'] | lower)"

  - name: set default dualtor facts
    set_fact:
      dual_tor_facts: {}
      mux_cable_facts: {}
    when: "'dualtor' not in topo"

  - name: gather dual ToR information
    dual_tor_facts:
      hostname: "{{ inventory_hostname }}"
      testbed_facts: "{{ testbed_facts }}"
      hostvars: "{{ hostvars }}"
      vm_config: "{{ vm_topo_config }}"
      port_alias: "{{ port_alias }}"
      vlan_intfs: "{{ vlan_intfs }}"
    delegate_to: localhost
    when: "'dualtor' in topo or 'cable' in topo"

  - name: gather mux cable information
    mux_cable_facts:
      topo_name: "{{ topo }}"
    delegate_to: localhost
    when: "'dualtor' in topo"

  - name: generate y_cable simulator driver
    include_tasks: dualtor/config_simulated_y_cable.yml
    vars:
      restart_pmon: no
    when: "'dualtor' in topo"

  - name: gather hwsku for LeafRouter that supports dualtor deployment
    set_fact:
      hwsku_list_dualtor_t1: "['ACS-MSN4600C', 'Arista-7260CX3-C64']"

  - name: enable tunnel_qos_remap for T1 in dualtor deployment
    set_fact:
      enable_tunnel_qos_remap: true
    when: "(('leafrouter' == (vm_topo_config['dut_type'] | lower)) or ('backendleafrouter' == (vm_topo_config['dut_type'] | lower))) and (hwsku in hwsku_list_dualtor_t1) and not (is_ixia_testbed)"

  - name: gather hwsku that supports ComputeAI deployment
    set_fact:
      hwsku_list_compute_ai: "['Cisco-8111-O64']"

  - name: enable ComputeAI deployment
    set_fact:
      enable_compute_ai_deployment: true
    when: "(hwsku in hwsku_list_compute_ai) and not (is_ixia_testbed)"

  - name: set default vm file path
    set_fact:
      vm_file: veos
    when: vm_file is not defined

  - set_fact:
      VM_topo: "{% if 'ptf' in topo %}False{% else %}True{% endif %}"
      remote_dut: "{{ ansible_ssh_host }}"

  - name: gather testbed VM information
    testbed_vm_info: base_vm={{ testbed_facts['vm_base'] }} topo={{ testbed_facts['topo'] }} vm_file={{ vm_file }}
    delegate_to: localhost
    when: "(VM_topo | bool) and ('cable' not in topo)"

  - name: find all vlan configurations for T0 topology
    vlan_config:
      vm_topo_config: "{{ vm_topo_config }}"
      port_alias: "{{ port_alias }}"
      vlan_config: "{{ vlan_config | default(None) }}"
    delegate_to: localhost
    when: "('host_interfaces_by_dut' in vm_topo_config) and ('tor' in vm_topo_config['dut_type'] | lower)"

  - name: find downlink portchannel configuration for T0 topology
    set_fact:
      portchannel_config: "{{ vm_topo_config['DUT']['portchannel_config'] | default({})}}"
    delegate_to: localhost
    when: "('host_interfaces_by_dut' in vm_topo_config) and ('tor' in vm_topo_config['dut_type'] | lower)"

  - name: find any tunnel configurations
    tunnel_config:
      vm_topo_config: "{{ vm_topo_config }}"
      tunnel_config: "{{ tunnel_config | default(None) }}"
    delegate_to: localhost

  - name: find all interface indexes mapping connecting to VM
    set_fact:
      interface_to_vms: "{{ interface_to_vms|default([]) + [ {'name': item.key, 'ports': item.value['interface_indexes'][dut_index|int] }] }}"
    with_dict: "{{ vm_topo_config['vm'] }}"
    when: "'cable' not in topo"

  - name: find all interface indexes connecting to VM
    set_fact:
      ifindex_to_vms: "{{ ifindex_to_vms|default([]) }} + {{ item.value['interface_indexes'][dut_index|int] }}"
    with_dict: "{{ vm_topo_config['vm'] }}"
    when: "'cable' not in topo"

  - name: find all interface names
    set_fact:
      intf_names: "{{ intf_names | default({}) | combine({item.0.name:  intf_names[item.0.name]|default([]) + [ port_alias[item.1]] }) }}"
    with_subelements:
      - "{{ interface_to_vms | default([]) }}"
      - "ports"
    when: "'cable' not in topo"

  # create map of VM to asic interface names
  - name: find all interface asic names
    set_fact:
      vm_asic_ifnames: "{{ vm_asic_ifnames | default({}) | combine({item.0.name: vm_asic_ifnames[item.0.name]|default([]) + [ front_panel_asic_ifnames[item.1]] }) }}"
      vm_asic_ids: "{{ vm_asic_ids | default({}) | combine({item.0.name: vm_asic_ids[item.0.name]|default([]) + [ front_panel_asic_ifs_asic_id[item.1]] }) }}"
    with_subelements:
      - "{{ interface_to_vms | default([]) }}"
      - "ports"
    when: front_panel_asic_ifnames != []

  - block:
      - name: Create new dictionary for my slot
        set_fact:
          new_asic_topo_config : "{{ new_asic_topo_config | default( { slot_num  : asic_topo_config.slot0 }) }}"

      - name: set asic_topo_config to new dictionary
        set_fact:
          asic_topo_config: "{{ new_asic_topo_config }}"

    when: switch_type is defined and switch_type == 'voq' and slot_num is defined and asic_topo_config|length > 0

  - name: create minigraph file in ansible minigraph folder
    template: src=templates/minigraph_template.j2
              dest=minigraph/{{ inventory_hostname}}.{{ topo }}.xml
    delegate_to: localhost
    when: local_minigraph is defined and local_minigraph|bool == true

  - block:
    - name: Init telemetry keys
      set_fact:
        server_key_t: ""
        server_cer_t: ""
        dsmsroot_key_t: ""
        dsmsroot_cer_t: ""
        dir_path_t: ""
        subject_server: ""
        subject_client: ""

    - name: read server key
      set_fact:
        server_key_t: "{{ telemetry_certs['server_key'] }}"
      when: telemetry_certs['server_key'] is defined

    - name: read server cer
      set_fact:
        server_cer_t: "{{ telemetry_certs['server_cer'] }}"
      when: telemetry_certs['server_cer'] is defined

    - name: read dsmsroot key
      set_fact:
        dsmsroot_key_t: "{{ telemetry_certs['dsmsroot_key'] }}"
      when: telemetry_certs['dsmsroot_key'] is defined

    - name: read dsmsroot cer
      set_fact:
        dsmsroot_cer_t: "{{ telemetry_certs['dsmsroot_cer'] }}"
      when: telemetry_certs['dsmsroot_cer'] is defined

    - name: read directory path
      set_fact:
        dir_path_t: "{{ telemetry_certs['dir_path'] }}"
      when: telemetry_certs['dir_path'] is defined

    - name: read server subject
      set_fact:
        subject_server: "{{ telemetry_certs['subject_server'] }}"
      when: telemetry_certs['subject_server'] is defined

    - name: read client subject
      set_fact:
        subject_client: "{{ telemetry_certs['subject_client'] }}"
      when: telemetry_certs['subject_client'] is defined

    - include_tasks: deploy_certs.yml
      vars:
        dir_path: "{{ dir_path_t }}"
        server_crt: "{{ server_cer_t }}"
        server_key: "{{ server_key_t }}"
        dsmsroot_cer: "{{ dsmsroot_cer_t }}"
        dsmsroot_key: "{{ dsmsroot_key_t }}"
        cert_subject: "{{ subject_server }}"
        root_subject: "{{ subject_client }}"

    when: deploy is defined and deploy|bool == true

  - block:
    - name: Init restapi keys
      set_fact:
        server_key_t: ""
        server_crt_t: ""
        dir_path_t: ""
        subject_t: ""

    - name: read server key
      set_fact:
        server_key_t: "{{ restapi_certs['server_key'] }}"
      when: restapi_certs['server_key'] is defined

    - name: read server crt
      set_fact:
        server_crt_t: "{{ restapi_certs['server_crt'] }}"
      when: restapi_certs['server_crt'] is defined

    - name: read subject
      set_fact:
        subject_t: "{{ restapi_certs['subject'] }}"
      when: restapi_certs['subject'] is defined

    - name: read directory path
      set_fact:
        dir_path_t: "{{ restapi_certs['dir_path'] }}"
      when: restapi_certs['dir_path'] is defined

    - include_tasks: deploy_certs.yml
      vars:
        dir_path: "{{ dir_path_t }}"
        server_crt: "{{ server_crt_t }}"
        server_key: "{{ server_key_t }}"
        cert_subject: "{{ subject_t }}"
    when: deploy is defined and deploy|bool == true

  - name: Set docker proxy
    block:
      - name: Ensures /etc/systemd/system/docker.service.d dir exists
        file:
          path: /etc/systemd/system/docker.service.d
          state: directory
          recurse: yes

      - name: Render docker proxy config
        template:
          src: 'templates/docker_http_proxy.j2'
          dest: '/etc/systemd/system/docker.service.d/http-proxy.conf'
          force: yes

      - name: restart docker service, let docker proxy takes effect
        systemd:
          state: restarted
          daemon_reload: yes
          name: docker

      - name: Wait 60s for docker containers to restart
        pause:
          seconds: 60
    become: true
    when: proxy_env is defined and deploy is defined and deploy|bool == true

  - block:
      - name: saved original minigraph file in SONiC DUT(ignore errors when file does not exist)
        shell: mv /etc/sonic/minigraph.xml /etc/sonic/minigraph.xml.orig
        become: true
        ignore_errors: true

      - name: create new minigraph file for SONiC device
        template: src=templates/minigraph_template.j2
                  dest=/etc/sonic/minigraph.xml
        become: true

      - name: Test if configlet script exist
        stat:
            path: vars/configlet/{{ topo }}/apply_clet.sh
        register: stat_result
        delegate_to: localhost

      - name: debug print stat_result
        debug:
          msg: Stat result is {{ stat_result }}

      - name: Copy corresponding configlet files if exist
        copy: src=vars/configlet/{{ topo }}/
              dest=/etc/sonic/
        become: true
        when: stat_result.stat.exists is defined and stat_result.stat.exists

      - name: Init account key and proxy
        set_fact:
            core_key: ""
            core_proxy: ""

      - name: Test if core_analyzer.rc.json exists
        stat:
            path: /etc/sonic/core_analyzer.rc.json
        register: rc_stat

      - name: read account key
        set_fact:
            core_key: "{{ corefile_uploader['azure_sonic_core_storage']['account_key'] }}"
        when: rc_stat.stat.exists is defined and rc_stat.stat.exists and corefile_uploader['azure_sonic_core_storage']['account_key'] is defined

      - name: read https proxy
        set_fact:
            core_proxy: "{{ corefile_uploader['env']['https_proxy'] }}"
        when: rc_stat.stat.exists is defined and rc_stat.stat.exists and corefile_uploader['env']['https_proxy'] is defined

      - name: Put secret in core_analyzer.rc.json
        lineinfile:
            name: /etc/sonic/core_analyzer.rc.json
            regexp: '(^.*)account_key'
            line: '\1account_key": "{{ core_key }}",'
            backrefs: yes
        become: true
        when: core_key != ""

      - name: Put https-proxy in core_analyzer.rc.json
        lineinfile:
            name: /etc/sonic/core_analyzer.rc.json
            regexp: '(^.*)https_proxy'
            line: '\1https_proxy": "{{ core_proxy }}"'
            backrefs: yes
        become: true
        when: core_proxy != ""

      - name: enable core uploader service
        become: true
        command: systemctl enable core_uploader.service
        when: core_key != ""

      - name: start core uploader service
        become: true
        command: systemctl start core_uploader.service
        when: core_key != ""

      - name: Replace snmp community string
        lineinfile:
            name: /etc/sonic/snmp.yml
            regexp: '^snmp_rocommunity:'
            line: 'snmp_rocommunity: {{ snmp_rocommunity }}'
        become: true

      - name: docker status
        shell: docker ps
        register: docker_status

      - debug: msg={{ docker_status.stdout_lines }}

      - name: start topology service for multi-asic platform
        become: true
        shell: systemctl start topology.service
        when: start_topo_service is defined and start_topo_service|bool == true
        register: result
        retries: 3
        delay: 10
        until: result is not failed

      - name: Cleanup /etc/sonic folder before loading new minigraph
        block:
        - name: Ensure /etc/sonic/acl.json is deleted
          become: true
          file:
            path: /etc/sonic/acl.json
            state: absent
        - name: Ensure /etc/sonic/port_config.json is deleted
          become: true
          file:
            path: /etc/sonic/port_config.json
            state: absent

      - name: find interface name mapping
        port_alias:
          hwsku: "{{ hwsku }}"
        when: topo == "mx"

      - name: Copy dhcp_server config hwsku {{ hwsku }}
        copy: src=golden_config_db/dhcp_server_mx.json
              dest=/tmp/dhcp_server.json
        become: true
        when: topo == "mx"

      - name: Generate golden_config_db.json
        generate_golden_config_db:
          topo_name: "{{ topo }}"
          port_index_map: "{{ port_index_map | default({}) }}"
        become: true

      - name: execute cli "config load_minigraph --override_config -y" to apply new minigraph
        become: true
        shell: config load_minigraph --override_config -y

      - name: Wait for switch to become reachable again
        become: false
        local_action: wait_for
        args:
          host: "{{ ansible_host }}"
          port: 22
          state: started
          search_regex: "OpenSSH_[\\w\\.]+ Debian"
          delay: 10
          timeout: 600
        changed_when: false

      - name: Sync DUT system time with NTP server
        block:
          - name: Wait for ntp.service restart after reload minigraph
            become: true
            service: name=ntp state=started

          - name: Stop ntp.service on DUT
            become: true
            service: name=ntp state=stopped

          - name: Sync DUT system time with NTP server
            become: true
            command: ntpd -gq
            ignore_errors: true
            async: 60
            poll: 10

          - name: Set the RTC from the system time
            become: true
            command: hwclock --systohc
            ignore_errors: true

          - name: Start ntp.service on DUT
            become: true
            service: name=ntp state=restarted enabled=true

      - name: config static route for trex traffic passthrough
        become: true
        command: "{{ item }}"
        with_items:
          - config route add prefix 48.0.0.0/8 nexthop 10.0.0.59
          - config route add prefix 16.0.0.0/8 nexthop 10.0.0.57
        when: topo == "wan-3link-tg"

      - name: execute cli "config bgp startup all" to bring up all bgp sessions for test
        become: true
        shell: config bgp startup all

      - name: Configure TACACS
        become: true
        shell: "{{ tacacs_config_cmd }}"
        loop:
          - config tacacs passkey {{ tacacs_passkey }}
          - config tacacs authtype pap
          - config aaa authentication login tacacs+
        loop_control:
          loop_var: tacacs_config_cmd
        ignore_errors: true
        when: tacacs_enabled_by_default is defined and tacacs_enabled_by_default|bool == true

      - name: execute configlet application script, which applies configlets in strict order.
        become: true
        shell: bash "/etc/sonic/apply_clet.sh"
        when: stat_result.stat.exists is defined and stat_result.stat.exists

      - block:
         - name: create isis config file for SONiC device
           template: src=templates/isis_config.j2
                     dest=/etc/sonic/isis_config.json
           become: true

         - name: active isis config
           become: true
           shell: sonic-cfggen -j /etc/sonic/isis_config.json -w

         #will remove below task, after isisd issue got fixed
         - name: restart bgp container
           become: true
           shell: docker restart bgp
        when: topo == "wan-ecmp" or topo == "wan-pub-isis"

      - block:
        - name: set the default grpc credential file path
          set_fact:
            grpc_credential_file: /etc/sonic/grpc_secrets.json

        - name: check if grpc credential file exists
          stat:
            path: "{{ grpc_credential_file }}"
          register: stat_result

        - block:
          - name: collect initial grpc credentials
            slurp:
              path: "{{ grpc_credential_file }}"
            register: grpc_credential_content

          - name: parse initial grpc credentials
            set_fact:
              grpc_secrets_before: "{{ grpc_credential_content.content | b64decode | from_json }}"

          - name: use insecure grpc for testing
            shell: "sed -E -i 's/\"type\": \"secure\"/\"type\": \"insecure\"/' {{ grpc_credential_file }}"
            become: true

          - name: collect current grpc credentials
            slurp:
              path: "{{ grpc_credential_file }}"
            register: grpc_credential_content

          - name: parse current grpc credentials
            set_fact:
              grpc_secrets_after: "{{ grpc_credential_content.content | b64decode | from_json }}"

          - name: show original grpc setting
            debug:
              var: grpc_secrets_before

          - name: show new grpc setting
            debug:
              var: grpc_secrets_after

          - name: restart the pmon service
            service:
              name: pmon
              state: restarted
            become: true

          when: stat_result.stat.exists

        when: "'dualtor-mixed' in topo or 'dualtor-aa' in topo"

      - name: execute cli "config save -y" to save current minigraph as startup-config
        become: true
        shell: config save -y
        when: save is defined and save|bool == true

      - name: remove running golden config file if exists
        become: True
        file: path=/etc/sonic/running_golden_config.json
              state=absent

      - name: remove running golden config files for all the asics if exists
        become: True
        file: path=/etc/sonic/running_golden_config{{ item }}.json
              state=absent
        with_sequence: start=0 end={{ num_asics - 1 }}
        when: num_asics > 1

      - name: cleanup all cached facts
        shell: python ../tests/common/cache/facts_cache.py
        delegate_to: localhost
        ignore_errors: true

      # In pr https://github.com/sonic-net/sonic-buildimage/pull/12109, it decrease the sshd timeout
      # which may cause timeout when executing `generate_dump -s yesterday`.
      # Increase this time during deploying minigraph
      - name: Reset sshd timeout
        become: True
        shell: sed -i "s/^ClientAliveInterval [0-9].*/ClientAliveInterval 900/g" /etc/ssh/sshd_config && systemctl restart sshd

    when: deploy is defined and deploy|bool == true
