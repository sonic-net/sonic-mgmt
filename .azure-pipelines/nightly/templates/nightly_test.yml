parameters:
  - name: TESTBED_NAME
    type: string

  - name: TESTBED_FILE
    type: string
    default: testbed.yaml
    values:
      - testbed.csv
      - testbed.yaml

  - name: NIGHTLY_TEST_TIMEOUT
    type: number
    default: 1800    # minutes, totally 30 hours

  # ============ Upgrade parameters ============
  - name: IMAGE_URL
    type: string
    default: ""

  - name: PREV_IMAGE_URL
    type: string
    default: ""

  - name: ALWAYS_INSTALL_NEW_IMAGE
    type: boolean
    default: true

  - name: UPGRADE_TYPE
    type: string
    default: sonic
    values:
      - sonic
      - onie

  - name: PAUSE_TIME
    type: number
    default: 0

  # Control the behavior if power cycle unreachable DUT
  # is allowed. Default: allowed (true)
  - name: POWER_CYCLE_UNREACHABLE_DUTS
    type: boolean
    default: true

  # Control the behavior of power cycle DUT before tests. If set to true,
  # DUTs will always be power cycled before tests. Default: false
  - name: ALWAYS_POWER_CYCLE_DUTS
    type: boolean
    default: false

  # ============ Deploy parameters ============
  - name: ENABLE_DATAACL
    type: boolean
    default: true

  # ============ Test Parameters ============
  - name: PY_SAITHRIFT_URL
    type: string
    default: ""

  - name: PTF_PORTMAP
    type: string
    default: ""

  # This is for the extra parameters to be passed to pytest by the "-e" option of run_tests.sh. For example,
  # to skip sanity check and disable log analyzer, the job yaml file calling this template can pass value
  # "--skip_sanity --disable_loganalyzer" to this EXTRA_PARAMS parameter.
  - name: EXTRA_PARAMS
    type: string
    default: ""

  # This is for other run_tests.sh options. For example, the run_tests.sh script supports "-S" option to skip
  # tests in specified folder. Assume a testbed needs to skip tests in folders like "platform_tests" and "dualtor"
  # sub-folders, the job yaml file calling this template can pass value '-S "platform_tests dualtor"' to
  # this TESTBED_SPECIFIC parameter.
  - name: TESTBED_SPECIFIC
    type: string
    default: ""

  - name: SKIP_SCRIPTS
    type: string
    default: "vrf/test_vrf.py vrf/test_vrf_attr.py mvrf/test_mgmtvrf.py"

stages:

  - stage: Test
    jobs:

      - job: NightlyTest
        pool: nightly
        timeoutInMinutes: ${{ parameters.NIGHTLY_TEST_TIMEOUT }}
        variables:
          - group: TBSHARE_SECRETS
          - group: KUSTO_SECRETS

        steps:

          - task: AzureKeyVault@1
            displayName: Get Secrets
            inputs:
              azureSubscription: 'Network Production Environment -- SONiC(9355ef17-3aa2-493a-94ab-a43a9bf8cd70)'
              KeyVaultName: 'SONiC'
              SecretsFilter: '*'
              RunAsPreJob: false

          - task: Bash@3
            displayName: Save Secrets
            inputs:
              targetType: 'inline'
              script: |
                # Download secrets.json from Azure Key Vault
                # The AzureKeyVault task automatically set variable for each secret found in key vault
                # Secrets available: nm-secrets, ansible-vault-passwd
                echo '$(nm-secrets)' > ansible/group_vars/all/secrets.json
                echo '$(ansible-vault-passwd)' > ansible/password.txt

                # decrypt the secret file
                md5sum ansible/group_vars/all/secrets.json
                ansible-vault decrypt ansible/group_vars/all/secrets.json --vault-password-file=ansible/password.txt

          - task: PythonScript@0
            displayName: Parse Testbed Info
            inputs:
              scriptSource: 'inline'
              script: |
                from __future__ import print_function
                import os, imp, sys

                testbed_module = imp.load_source('testbed', 'tests/common/testbed.py')
                testbed_name = '${{ parameters.TESTBED_NAME }}'
                testbed_file = '${{ parameters.TESTBED_FILE }}'
                tbinfo = testbed_module.TestbedInfo('ansible/{}'.format(testbed_file))
                target_testbed = tbinfo.testbed_topo.get(testbed_name, None)
                if not target_testbed:
                    print('Testbed {} not found!'.format(testbed_name))
                    sys.exit(1)
                dut_list = target_testbed.get('duts', [])
                dut_list_str = ' '.join(x for x in dut_list)

                print('Basic info of testbed {}:'.format(testbed_name))
                print('    INVENTORY_NAME={}'.format(target_testbed['inv_name']))
                print('     TOPOLOGY_NAME={}'.format(target_testbed['topo']['name']))
                print('     TOPOLOGY_TYPE={}'.format(target_testbed['topo']['type']))
                print('          DUT_LIST={}'.format(dut_list_str))

                # Below code can create dynamic azure pipeline variables
                # Reference: https://docs.microsoft.com/en-us/azure/devops/pipelines/process/variables?view=azure-devops&tabs=yaml%2Cbatch#set-a-job-scoped-variable-from-a-script
                print('##vso[task.setvariable variable=INVENTORY_NAME;]{}'.format(target_testbed['inv_name']))
                print('##vso[task.setvariable variable=TOPOLOGY_NAME;]{}'.format(target_testbed['topo']['name']))
                print('##vso[task.setvariable variable=TOPOLOGY_TYPE;]{}'.format(target_testbed['topo']['type']))
                print('##vso[task.setvariable variable=DUT_LIST;]{}'.format(dut_list_str))

          - task: PythonScript@0
            displayName: Lock Testbed
            inputs:
              scriptSource: 'filePath'
              scriptPath: ./.azure-pipelines/nightly/templates/lock_release.py
              arguments: lock
            env:
                TESTBED_NAME: ${{ parameters.TESTBED_NAME }}
                TBSHARE_AAD_CLIENT_ID: $(TBSHARE_AAD_CLIENT_ID)
                TBSHARE_AAD_CLIENT_SECRET: $(TBSHARE_AAD_CLIENT_SECRET)

          - task: Bash@3
            displayName: "Upgrade Image"
            inputs:
              targetType: 'inline'
              script: |
                set -x

                if [[ -z "$IMAGE_URL" ]]; then
                    echo "Skipping image upgrading ..."
                    exit 0
                fi

                if [[ -z "$PREV_IMAGE_URL" ]]; then
                    PREV_IMAGE_URL="$IMAGE_URL.PREV.1"
                fi

                cd ansible

                if [[ ${{ parameters.ALWAYS_POWER_CYCLE_DUTS }} == True ]]; then
                    for dut in $(DUT_LIST); do
                        echo "Power cycling ${dut} ..."
                        ./devutils -i $(INVENTORY_NAME) -a pdu_off -j -l ${dut}
                        sleep 10
                        ./devutils -i $(INVENTORY_NAME) -a pdu_on -j -l ${dut}
                    done

                    # Add some sleep to allow power cycled DUTs to come back
                    sleep 180
                elif [[ ${{ parameters.POWER_CYCLE_UNREACHABLE_DUTS }} == True ]]; then
                    NEEDS_SLEEP='No'
                    for dut in $(DUT_LIST); do
                        echo "Checking DUT ${dut} ..."
                        RC=0
                        ./devutils -i $(INVENTORY_NAME) -a ping -j -l ${dut} | grep -q Success || RC=$?
                        if [[ RC -ne 0 ]]; then
                            echo "Power cycling ${dut} ..."
                            ./devutils -i $(INVENTORY_NAME) -a pdu_off -j -l ${dut}
                            sleep 10
                            ./devutils -i $(INVENTORY_NAME) -a pdu_on -j -l ${dut}
                            NEEDS_SLEEP='Yes'
                        fi
                    done
                    if [[ x"${NEEDS_SLEEP}" == x"Yes" ]]; then
                        # Add some sleep to allow power cycled DUTs to come back
                        sleep 180
                    fi
                fi

                if [[ ${{ parameters.ALWAYS_INSTALL_NEW_IMAGE }} == True && "${{ parameters.UPGRADE_TYPE }}" == "sonic" ]]; then
                    ANSIBLE_FORCE_COLOR=true ansible-playbook upgrade_sonic.yml \
                        -i $(INVENTORY_NAME) \
                        -e testbed_name=${{ parameters.TESTBED_NAME }} \
                        -e image_url="$PREV_IMAGE_URL" \
                        -e upgrade_type=${{ parameters.UPGRADE_TYPE }} \
                        --vault-password-file password.txt \
                        -e pause_time=60 -vv || true
                fi
                ANSIBLE_FORCE_COLOR=true ansible-playbook upgrade_sonic.yml \
                    -i $(INVENTORY_NAME) \
                    -e testbed_name=${{ parameters.TESTBED_NAME }} \
                    -e image_url=$IMAGE_URL \
                    -e upgrade_type=${{ parameters.UPGRADE_TYPE }} \
                    --vault-password-file password.txt \
                    -e pause_time=${{ parameters.PAUSE_TIME }} -vv

                sleep 180
            env:
              IMAGE_URL: ${{ parameters.IMAGE_URL }}
              PREV_IMAGE_URL: ${{ parameters.PREV_IMAGE_URL }}

          - task: Bash@3
            displayName: Deploy Minigraph
            inputs:
              targetType: 'inline'
              script: |
                set -x

                if [[ ${{ parameters.ENABLE_DATAACL }} == True ]]; then
                    CONFIG_PARAMS="$CONFIG_PARAMS -e enable_data_plane_acl=true"
                else
                    CONFIG_PARAMS="$CONFIG_PARAMS -e enable_data_plane_acl=false"
                fi
                cd ansible

                # ./testbed-cli.sh restart-ptf ${{ parameters.TESTBED_NAME }} password.txt
                ./testbed-cli.sh deploy-mg ${{ parameters.TESTBED_NAME }} $INVENTORY_NAME password.txt $CONFIG_PARAMS
                sleep 180
            env:
              INVENTORY_NAME: $(INVENTORY_NAME)

          - task: Bash@3
            displayName: Run Tests
            inputs:
              targetType: 'inline'
              script: |
                set -x

                BASE_PATH=`pwd`
                PARAMS="--allow_recover --showlocals --assert plain -rav --collect_techsupport=False --deep_clean"

                if [[ -n $PY_SAITHRIFT_URL ]]; then
                    PARAMS="$PARAMS --py_saithrift_url=$PY_SAITHRIFT_URL"
                fi

                if [[ -n $PTF_PORTMAP ]]; then
                    PARAMS="$PARAMS --ptf_portmap=$PTF_PORTMAP"
                fi

                if [[ -n $EXTRA_PARAMS ]]; then
                    PARAMS="$PARAMS $EXTRA_PARAMS"
                fi

                EXECUTION_TOPOLOGY=$(TOPOLOGY_TYPE)
                if [[ "$TOPOLOGY_TYPE" != "tgen" ]]; then
                    EXECUTION_TOPOLOGY="$EXECUTION_TOPOLOGY,any"
                fi

                if [[ "$TOPOLOGY_NAME" == *"dualtor"* ]]; then
                    EXECUTION_TOPOLOGY="$EXECUTION_TOPOLOGY,dualtor"
                fi

                rm -fr results     # Clear any possible collected results of previous run

                cd tests

                # '$(INVENTORY_NAME)' and '$(TOPOLOGY_TYPE)' are dynamic variables generated in step_parse_testbed_info.yml
                ./run_tests.sh -n ${{ parameters.TESTBED_NAME }} \
                    -s "${{ parameters.SKIP_SCRIPTS }}" \
                    -i $BASE_PATH/ansible/$(INVENTORY_NAME),$BASE_PATH/ansible/veos \
                    -m individual \
                    -t "$EXECUTION_TOPOLOGY" \
                    -r \
                    ${{ parameters.TESTBED_SPECIFIC }} \
                    -e "$PARAMS"
                exit 0
            env:
              PY_SAITHRIFT_URL: ${{ parameters.PY_SAITHRIFT_URL }}
              PTF_PORTMAP: ${{ parameters.PTF_PORTMAP }}
              EXTRA_PARAMS: ${{ parameters.EXTRA_PARAMS }}

          - publish: tests/logs
            displayName: "Archive test logs"
            artifact: ${{ parameters.TESTBED_NAME}}.nightly.log@$(System.JobAttempt)
            condition: always()

          - task: PublishTestResults@2
            displayName: Publish test results
            inputs:
              testResultsFiles: 'tests/logs/**/*.xml'
              testRunTitle: ${{ parameters.TESTBED_NAME}}.nightly
            condition: always()

          - task: PythonScript@0
            displayName: Release Testbed
            inputs:
              scriptSource: 'filePath'
              scriptPath: ./.azure-pipelines/nightly/templates/lock_release.py
              arguments: release
            env:
                TESTBED_NAME: ${{ parameters.TESTBED_NAME }}
                TBSHARE_AAD_CLIENT_ID: $(TBSHARE_AAD_CLIENT_ID)
                TBSHARE_AAD_CLIENT_SECRET: $(TBSHARE_AAD_CLIENT_SECRET)
            condition: always()

          - task: CopyFiles@2
            displayName: Collect result files
            inputs:
              Contents: |
                tests/logs/**/*.xml
                tests/logs/platform_tests/test_*_reboot*.json
              TargetFolder: results
              CleanTargetFolder: true
            condition: always()

          - task: Bash@3
            displayName: Upload Test Results
            inputs:
              targetType: 'inline'
              script: |
                set -x
                echo "Activate python3 virtual environment"
                source /var/AzDevOps/env-python3/bin/activate

                cd test_reporting
                pip3 install -r requirements.txt

                python3 junit_xml_parser.py -d ../results -o tr.json

                # temporary workaround to allow reboot timing data upload
                # After recent test change, the file names get DUT name in them
                # A more permanent fix is needed in report_uploader.py to accept file names with DUT name
                reboot_path=../results/tests/logs/platform_tests/
                mv $reboot_path/test_fast_reboot*_summary.json $reboot_path/test_fast_reboot_summary.json || true
                mv $reboot_path/test_fast_reboot*_report.json  $reboot_path/test_fast_reboot_report.json || true
                mv $reboot_path/test_warm_reboot*_summary.json $reboot_path/test_warm_reboot_summary.json || true
                mv $reboot_path/test_warm_reboot*_report.json  $reboot_path/test_warm_reboot_report.json || true
                report_upload_files="../results $(find ../results -type f -iname 'test_*_reboot*.json')"

                python3 report_uploader.py -c "test_result" -e "$(Build.DefinitionName)#$(Build.BuildId)" $report_upload_files SonicTestData
            condition: always()
            env:
              TEST_REPORT_INGEST_KUSTO_CLUSTER: $(TEST_REPORT_INGEST_KUSTO_CLUSTER)
              TEST_REPORT_AAD_TENANT_ID: $(TEST_REPORT_AAD_TENANT_ID)
              TEST_REPORT_AAD_CLIENT_ID: $(TEST_REPORT_AAD_CLIENT_ID)
              TEST_REPORT_AAD_CLIENT_KEY: $(TEST_REPORT_AAD_CLIENT_KEY)
